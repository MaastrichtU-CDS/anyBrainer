# anyBrainer ðŸ§ 
**anyBrainer** is a PyTorch Lightning + MONAIâ€“based framework for **pretraining and finetuning foundation models** for brain MRI analysis.  
It extends MONAI and Lightning with custom transforms, optimizers/schedulers, and inferers to provide a flexible end-to-end pipeline for a wide range of downstream tasks.

The framework supports **contrastive learning pretraining** as well as downstream tasks:
- **Classification** (e.g., brain infarct detection)
- **Segmentation** (e.g., meningioma segmentation)
- **Regression** (e.g., brain age prediction)
- **Multimodal fusion** setups

anyBrainer was used for the [MICCAI FOMO25 challenge](https://fomo25.grand-challenge.org/) across **all tasks**:
- Pretraining  
- Finetuning for classification, segmentation, and regression  
- Inference and containerized submission

---

## Features âœ¨
- **Config-driven workflows**: Run pretraining/finetuning/inference via `.yaml` configs  
  (`pretrain_cl.yaml`, `finetune_cls.yaml`, `finetune_seg.yaml`, `finetune_reg.yaml`)  
- **Custom MONAI transforms** for MRI-specific augmentation and preprocessing  
- **Multi-param optimizer & scheduler factories** for flexible training setups  
- **Custom inferers** for efficient sliding-window and multimodal inference  
- **Contrastive learning setup** for foundation model pretraining  
- Built on **PyTorch Lightning** for reproducibility and scalability
- Compatible with **Weights & Biases** logging for detailed experiment tracking
- **Containerization-ready**: inference scripts and [Apptainer](https://apptainer.org/) specs in [`app/`](./app)  

---

## Installation

Clone the repository and install via:

```bash
# For basic dependencies:
pip install -e .

# For all dependencies:
pip install -e ".[dev,test]"
```

---

## Usage

Training and inference are fully config-driven. Example configs are provided in the repo.

```bash
# Pretraining (contrastive)
anyBrainer TrainWorkflow "pretrain_cl.yaml"

# Finetuning for classification
anyBrainer CVWorkflow "finetune_cls.yaml"

# Finetuning for segmentation
anyBrainer CVWorkflow "finetune_seg.yaml"

# Finetuning for regression
anyBrainer CVWorkflow "finetune_reg.yaml"
```

---

## Project Structure ðŸ“‚

anyBrainer/
â”œâ”€â”€ app/ # Inference scripts and Apptainer files (containerization)
â”œâ”€â”€ ckpts/ # Checkpoints from training runs
â”œâ”€â”€ config_files/ # Example / user-provided configs
â”œâ”€â”€ scripts/ # Utility scripts for experiments
â”œâ”€â”€ src/ # Source code
â”‚ â””â”€â”€ anyBrainer/ # Main package
â”‚ â”œâ”€â”€ config/ # Config management
â”‚ â”œâ”€â”€ core/ # Core modules: data, engines, networks, losses, transforms, etc.
â”‚ â”œâ”€â”€ factories/ # Factories for models, optimizers, schedulers
â”‚ â”œâ”€â”€ interfaces/ # Base classes and interfaces
â”‚ â”œâ”€â”€ log/ # Logging utilities
â”‚ â”œâ”€â”€ registry/ # Registries for models, transforms, losses, etc.
â”‚ â”œâ”€â”€ main.py # CLI entry point
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ templates/ # Template YAML configs
â”œâ”€â”€ tests/ # Unit and integration tests
â”œâ”€â”€ finetune_cls.yaml # Example config: classification
â”œâ”€â”€ finetune_reg.yaml # Example config: regression
â”œâ”€â”€ finetune_seg.yaml # Example config: segmentation
â”œâ”€â”€ pretrain_cl.yaml # Example config: contrastive pretraining
â”œâ”€â”€ pyproject.toml # Project dependencies
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md

---

## Citation ðŸ“–

If you use anyBrainer in your research, please cite this repository:

@misc{anybrainer2025,
  title        = {anyBrainer: A PyTorch Lightning + MONAI Framework for Brain MRI Pretraining and Finetuning},
  author       = {Petros Koutsouvelis},
  year         = {2025},
  howpublished = {\url{https://github.com/...}}
}

---

License ðŸ“œ

This project is released under the MIT License. See LICENSE(./LICENSE) for details.
